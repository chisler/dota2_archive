{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('selected_team_match_info.jsonlines', 'r')\n",
    "alldata = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#json.loads(alldata[0])['picks_bans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parseMatch(match, params_list):\n",
    "    values = [None for _ in range(len(params_list))]\n",
    "    return_dict = dict(zip(params_list, values))\n",
    "    for param in params_list:\n",
    "        try:\n",
    "            if param == 'radiant_win':\n",
    "                if match[param]:\n",
    "                    return_dict[param] = 1\n",
    "                else:\n",
    "                    return_dict[param] = 0\n",
    "            else:\n",
    "                return_dict[param] = match[param]\n",
    "        except:\n",
    "            return_dict[param] = None\n",
    "                \n",
    "    return return_dict\n",
    "        \n",
    "\n",
    "#print(parseMatch(json.loads(alldata[0]), ['radiant_win', 'huinner']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parsePicsBans(match):\n",
    "    radiant_pick = []\n",
    "    dire_pick = []\n",
    "    \n",
    "    try:\n",
    "        picks_bans = match['picks_bans']\n",
    "        for hero in picks_bans:\n",
    "            if hero['is_pick'] == True:\n",
    "                if hero['team'] == 1:\n",
    "                    radiant_pick.append(int(hero['hero_id']))\n",
    "                else:\n",
    "                    dire_pick.append(int(hero['hero_id']))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return radiant_pick, dire_pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateDataFrame(alldata, params_list):\n",
    "    params_list = ['match_id'] + params_list\n",
    "    return_data = pd.DataFrame(columns = params_list)\n",
    "    \n",
    "    for match_string in alldata:\n",
    "        match = json.loads(match_string)\n",
    "        match_data = parseMatch(match, params_list)\n",
    "        \n",
    "        return_data.loc[len(return_data)] = match_data\n",
    "    \n",
    "    return return_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teams_data = generateDataFrame(alldata, ['radiant_name', 'dire_name', 'radiant_win'])\n",
    "teams_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teams = np.concatenate((teams_data.dire_name.unique(), teams_data.radiant_name.unique())) \n",
    "raiant_counts = teams_data.radiant_name.value_counts()\n",
    "dire_counts = teams_data.dire_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#READ DATA IF YOU NEED\n",
    "hdr = pd.read_csv('dotadatadruje.csv')\n",
    "winrates = pd.read_csv('TimeWinRates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "only_heroes_data = pd.DataFrame(columns = ['match_id'] + ['hero_' + str(i) for i in range(1,114)] + ['radiant_name', 'dire_name', 'winner'])\n",
    "winner_cell = 116\n",
    "\n",
    "error_count = 0\n",
    "\n",
    "for match_string in alldata:\n",
    "    match = json.loads(match_string)\n",
    "    match_results = [0 for i in range(116)] + ['']\n",
    "    match_results_inverse = [0 for i in range(116)] + ['']\n",
    "    \n",
    "    try:\n",
    "        match_info =  parseMatch(match, ['match_id', 'radiant_win', 'radiant_name', 'dire_name'])\n",
    "        radiant_pick, dire_pick = parsePicsBans(match)\n",
    "        \n",
    " \n",
    "        for hero in radiant_pick:\n",
    "            match_results[hero] = 1\n",
    "            match_results_inverse[hero] = -1\n",
    "        for hero in dire_pick:\n",
    "            match_results[hero] = -1\n",
    "            match_results_inverse[hero] = 1\n",
    "        match_results[0] = match_info['match_id']\n",
    "        match_results[winner_cell] = match_info['radiant_win']\n",
    "        match_results[winner_cell - 1] = match_info['dire_name']\n",
    "        match_results[winner_cell - 2] = match_info['radiant_name']\n",
    "         \n",
    "        match_results_inverse[0] = match_info['match_id']\n",
    "        match_results_inverse[winner_cell] = 1 - match_info['radiant_win']\n",
    "        match_results_inverse[winner_cell - 1] = match_info['radiant_name']\n",
    "        match_results_inverse[winner_cell - 2] = match_info['dire_name']\n",
    "\n",
    "        if match_info['radiant_win'] == None:\n",
    "            print(match_info['radiant_win'])\n",
    "    \n",
    "    except:\n",
    "        error_count += 1\n",
    "\n",
    "    only_heroes_data.loc[len(only_heroes_data)] = match_results\n",
    "    only_heroes_data.loc[len(only_heroes_data)] = match_results_inverse\n",
    "    \n",
    "only_heroes_data = only_heroes_data[only_heroes_data.winner != '']\n",
    "only_heroes_data.dropna(inplace=True)\n",
    "only_heroes_data = only_heroes_data[only_heroes_data.columns[1:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, row in only_heroes_data[only_heroes_data.columns[:-1]].iterrows():\n",
    "    if sum(row) != 0:\n",
    "        print sum(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "only_heroes_data = only_heroes_data[only_heroes_data.winner != '']\n",
    "only_heroes_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rank = pd.read_csv('rank_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "only_heroes_data.to_csv('only_heroes_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addRanking(data, rank):\n",
    "    avr_rank = 25\n",
    "    data['dire_rank'] = avr_rank\n",
    "    data['radiant_rank'] = avr_rank\n",
    "    for index, row in data.iterrows():\n",
    "        if row['dire_name'] in rank['0'].values:\n",
    "            data.loc[index, 'dire_rank'] = rank[rank['0'] == row['dire_name']]['1'].values[0]\n",
    "        if row['radiant_name'] in rank['0'].values:\n",
    "            data.loc[index, 'radiant_rank'] = rank[rank['0'] == row['radiant_name']]['1'].values[0]        \n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdr = addRanking(only_heroes_data, rank)\n",
    "#only_heroes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdr = hdr.reindex(columns = np.concatenate([hdr.columns[:-5].values, hdr.columns[-2:].values, hdr.columns[-5:-2].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del hdr['radiant_name']\n",
    "del hdr['dire_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdr.to_csv('hdr.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rates = pd.read_csv('rates_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdr.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hdr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdr_close_rates = hdr.loc[abs(hdr['dire_rank'] - hdr['radiant_rank']) < 3,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hdr_close_rates[np.concatenate([hdr_close_rates.columns[:-3].values, hdr_close_rates.columns[-1:]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdr_close_rates.to_csv('hdr_close_rates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del hdr_close_rates['radiant_name']\n",
    "del hdr_close_rates['dire_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdr_close_rates = pd.read_csv('hdr_close_rates.csv')\n",
    "del hdr_close_rates['radiant_name']\n",
    "del hdr_close_rates['dire_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE I SHUFFLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitData(data):\n",
    "    shuffled_data = data.iloc[np.random.permutation(len(data))]\n",
    "    shuffled_data.reset_index(drop=True)\n",
    "\n",
    "    train_data = shuffled_data[:int(len(shuffled_data) * 0.7)]\n",
    "    validation_data = shuffled_data[int(len(shuffled_data) * 0.7):int(len(shuffled_data) * 0.85)]\n",
    "    test_data = shuffled_data[int(len(shuffled_data) * 0.85):]\n",
    "    \n",
    "    return train_data, validation_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#only_heroes_train_data, only_heroes_validation_data, only_heroes_test_data = splitData(only_heroes_data)\n",
    "\n",
    "def prepareAllData(data):\n",
    "    train_data, validation_data, test_data = splitData(data)\n",
    "\n",
    "    X_train = train_data[data.columns[:-1]]\n",
    "    #X_train = X_train.drop(u'Unnamed: 0', axis = 1 )\n",
    "    Y_train = train_data[data.columns[-1:]].values[:,-1].astype('float')\n",
    "\n",
    "    X_validation = validation_data[data.columns[:-1]]\n",
    "    #X_test = X_test.drop(u'Unnamed: 0', axis = 1)\n",
    "    Y_validation = validation_data[data.columns[-1:]].values[:,-1].astype('float')\n",
    "\n",
    "    X_test = test_data[data.columns[:-1]]\n",
    "    #X_test = X_test.drop(u'Unnamed: 0', axis = 1)\n",
    "    Y_test = test_data[data.columns[-1:]].values[:,-1].astype('float')\n",
    "\n",
    "    return X_train, Y_train, X_validation, Y_validation, X_test, Y_test\n",
    "\n",
    "#X_train, Y_train, X_validation, Y_validation, X_test, Y_test = prepareAllData(hdr_close_rates[np.concatenate([hdr_close_rates.columns[:-3].values, hdr_close_rates.columns[-1:]])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hdr_crc = cut(hdr_close_rates, 2)\n",
    "train, train_label, val, val_label, test, test_label = prepareAllData(hdr_close_rates)\n",
    "#train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut(df, num):\n",
    "    return df[df.columns[:-num]]\n",
    "\n",
    "train_cut = cut(train, 2)\n",
    "test_cut = cut(test, 2)\n",
    "valid_cut = cut(val, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def countCorrect(pred, label, round_flag = False):\n",
    "    bin_pred = pred #[round(i) for i in range(len(pred))]\n",
    "    if round_flag:\n",
    "        bin_pred = np.zeros(len(pred))\n",
    "        bin_pred[pred > 0.5] = 1\n",
    "    count = 0\n",
    "    for i in bin_pred == label:\n",
    "        if i:\n",
    "            count += 1\n",
    "\n",
    "    return float(count)/len(bin_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE I TRY LOGREG FROM SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm as svm_classifier\n",
    "\n",
    "def runLogReg(tr, tr_label, te, te_label):\n",
    "    logreg = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    logreg.fit(tr.values, tr_label)\n",
    "\n",
    "\n",
    "    logreg_pred = logreg.predict_proba(te)[:, 1]\n",
    "\n",
    "    print('logreg: {0}'.format(countCorrect(logreg_pred, te_label, True)))\n",
    "    \n",
    "    return logreg_pred, logreg\n",
    "\n",
    "def runSVM(tr, tr_label, te, te_label):\n",
    "    svm = svm_classifier.SVC(kernel='rbf', probability=True,)\n",
    "    svm.fit(tr, tr_label)\n",
    "\n",
    "\n",
    "    svm_pred = svm.predict_proba(te)[:, 1]\n",
    "    print(svm_pred[:10])\n",
    "    print('svm: {0}'.format(countCorrect(svm_pred, te_label, True)))\n",
    "    \n",
    "    return svm_pred, svm\n",
    "    \n",
    "def runNN(tr, tr_label, te, te_label, n_neighbors = 5):\n",
    "    #n_neighbors = 3\n",
    "    nn = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "    nn.fit(tr, tr_label)\n",
    "\n",
    "    nn_pred = nn.predict_proba(te)[:, 1]\n",
    "\n",
    "    print('NN: {0}'.format(countCorrect(nn_pred, te_label, True)))\n",
    "    \n",
    "    return nn_pred, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runFullStack(train, train_label, test, test_label):\n",
    "    #nn_pred, nn = runNN(train, train_label, test, test_label)\n",
    "    svm_pred, svm = runSVM(train, train_label, test, test_label)\n",
    "    logreg_pred, logreg = runLogReg(train, train_label, test, test_label)\n",
    "    return svm_pred, svm, logreg_pred, logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-1abaf42ac3b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogreg_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunFullStack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "nn_pred, nn, svm_pred, svm, logreg_pred, logreg = runFullStack(train, train_label, test, test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = train[7:8].values\n",
    "logreg.predict_proba(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t[t == 1.1] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t[t == 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm.predict_proba(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE WE GO WITH XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train_cut, train_label)\n",
    "dvalidation = xgb.DMatrix(valid_cut, val_label)\n",
    "dtest = xgb.DMatrix(test_cut, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify parameters via map, definition are same as c++ version\n",
    "param = {'max_depth':5, 'eval_metric' : 'logloss', 'eta':0.1, }\n",
    "\n",
    "# specify validations set to watch performance\n",
    "watchlist  = [(dvalidation,'eval'), (dtrain,'train')]\n",
    "num_round = 6\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist, verbose_eval=True)\n",
    "\n",
    "# this is prediction\n",
    "#preds = bst.predict(dtest)\n",
    "#labels = dtest.get_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bst_preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(countCorrect(bst_preds, test_label, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_pred_asasa = np.zeros(len(bst_preds))\n",
    "bin_pred_asasa[bst_preds > 0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bin_pred_asasa == test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PYBRAIN MSFK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.datasets import SupervisedDataSet\n",
    "from pybrain.supervised.trainers import BackpropTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = buildNetwork(115, 5, 1)\n",
    "ds = SupervisedDataSet(115, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train = X_train\n",
    "train['winner'] = train_label\n",
    "val['winner'] = val_label\n",
    "#test = X_test\n",
    "test['winner'] = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in train.values:\n",
    "    #print(row[:-1])\n",
    "    indata = row[:-1]\n",
    "    outdata = row[len(row) - 1]\n",
    "    ds.addSample(indata,outdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = BackpropTrainer(net, ds)\n",
    "#trainer = BackpropTrainer( fnn, dataset=trndata, momentum=0.1, verbose=True, weightdecay=0.01)\n",
    "trainer.trainEpochs(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NNpred = []\n",
    "for row in test.values:\n",
    "    NNpred.append(net.activate(row[:-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binaryNNpred = [round(i) for i in NNpred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "binaryNNpred == test_label:\n",
    "    if i:\n",
    "        count += 1\n",
    "\n",
    "print(float(count)/len(binaryNNpred))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calcErr(pred, label):\n",
    "    binaryNNpred = [round(i) for i in pred]\n",
    "    count = 0\n",
    "    for i in range(len(label)):\n",
    "        if binaryNNpred[i] == label[i]:\n",
    "            count += 1\n",
    "\n",
    "    return (float(count)/len(binaryNNpred))\n",
    "\n",
    "\n",
    "def runNN(train_data, valid_data, test_data, rounds):\n",
    "    net = buildNetwork(len(train_data.columns[:-1]), 10, 1)\n",
    "    ds = SupervisedDataSet(len(train_data.columns[:-1]), 1)\n",
    "    \n",
    "    for row in train_data.values:\n",
    "        indata = row[:-1]\n",
    "        outdata = row[len(row) - 1]\n",
    "        ds.addSample(indata,outdata)\n",
    "    trainer = BackpropTrainer(net, ds, learningrate=0.05)\n",
    "    #trainer = BackpropTrainer( fnn, dataset=trndata, momentum=0.1, verbose=True, weightdecay=0.01)\n",
    "    \n",
    "    NNpred = []\n",
    "    for row in valid_data.values:\n",
    "        NNpred.append(net.activate(row[:-1]))\n",
    "    label = valid_data.winner.values.astype('float')\n",
    "    \n",
    "    err_curr = calcErr(NNpred, label)\n",
    "    err_prev = 1000\n",
    "    #while err_curr >= err_prev:\n",
    "    for i in range(rounds):\n",
    "        trainer.trainEpochs(1)\n",
    "    \n",
    "        NNpred = []\n",
    "        for row in valid_data.values:\n",
    "            NNpred.append(net.activate(row[:-1]))\n",
    "        \n",
    "        label = valid_data.winner.values.astype('float')\n",
    "    \n",
    "        err_prev = err_curr\n",
    "        err_curr = calcErr(NNpred, label)\n",
    "        print ('curr: {0}'.format(err_curr))\n",
    "        print ('prev: {0}'.format(err_prev))\n",
    "\n",
    "    return err_curr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print runNN(train, val, test, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#json.loads(alldata[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def searchFor31(picksbans, hero_id):\n",
    "    for hero in picksbans:\n",
    "        if hero['hero_id'] == hero_id:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def checkHero(hero_id):\n",
    "    for match_string in alldata:\n",
    "        match = json.loads(match_string)\n",
    "        try:\n",
    "            if searchFor31(match['picks_bans'], hero_id):\n",
    "                return True\n",
    "        except:\n",
    "            pass\n",
    "    return False\n",
    "\n",
    "for i in range(130):\n",
    "    if not checkHero(i):\n",
    "        print i\n",
    "\n",
    "checkHero(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json.loads(alldata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "winrates = pd.read_csv('TimeWinRates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACTORIZATION MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from kaggler.online_model import FM\n",
    "import scipy\n",
    "\n",
    "def runFM(tr, tr_label, te, te_label):\n",
    "    fm = FM(n=len(tr.columns), # number of features\n",
    "    epoch=20, # number of epochs\n",
    "    dim=4, # size of factors for interactions\n",
    "    a=.1) \n",
    "    \n",
    "    fm.fit(scipy.sparse.csr_matrix(tr.values), tr_label)\n",
    "\n",
    "    fm_pred = fm.predict(scipy.sparse.csr_matrix(te.values))\n",
    "    print(countCorrect(fm_pred, te_label, True))\n",
    "    return fm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFACTOR ONE VERY HOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "double_hdr = pd.DataFrame(columns = ['r_hero_'+str(i) for i in range(114)] + ['d_hero_'+str(i) for i in range(114)] + ['dire_rank', 'radiant_rank', 'winner'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "double_hdr = pd.DataFrame(columns = ['r_hero_'+str(i) for i in range(114)] + ['d_hero_'+str(i) for i in range(114)] + ['dire_rank', 'radiant_rank', 'winner'], index = hdr.index)\n",
    "c = 0\n",
    "for index, row in hdr.iterrows():\n",
    "    radiant_pick = []\n",
    "    dire_pick = []\n",
    "\n",
    "    for i in range(len(row.values[:-1])):\n",
    "        if row.values[i] == 1:\n",
    "            radiant_pick.append(i + 1)\n",
    "        elif row.values[i] == -1:\n",
    "            dire_pick.append(i + 1)\n",
    "\n",
    "    double_hdr.loc[len(double_hdr)] = np.zeros(len(double_hdr.columns))\n",
    "    for i in dire_pick: \n",
    "        #pass\n",
    "        double_hdr.loc[index, 'd_hero_'+str(i)] = 1\n",
    "    for i in radiant_pick: \n",
    "    #    #pass\n",
    "        double_hdr.loc[index, 'r_hero_'+str(i)] = 1\n",
    "    \n",
    "    double_hdr.loc[index, 'radiant_rank'] = row['radiant_rank']\n",
    "    double_hdr.loc[index, 'dire_rank'] = row['dire_rank']\n",
    "    if int(row['winner']) == 1:\n",
    "        double_hdr.loc[index, 'winner'] = 1\n",
    "    else:\n",
    "        double_hdr.loc[index, 'winner'] = 0\n",
    "    #double_hdr.loc[index, 'winner'] = row['winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "double_hdr.to_csv('double_hdr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "double_hdr = pd.read_csv('double_hdr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for index, row in hdr.iterrows():\n",
    "\n",
    "#    if row['winner'] == 1:\n",
    "#        print(row['winner'])\n",
    "#sum(double_hdr[:500].winner.values)\n",
    "double_hdr = double_hdr.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del double_hdr['dire_rank']\n",
    "del double_hdr['radiant_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del double_hdr['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_train, d_train_label, d_valid, d_valid_label, d_test, d_test_label = prepareAllData(double_hdr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51060022  0.43870837  0.51559046  0.48228544  0.42309435  0.46430858\n",
      "  0.46517726  0.54476715  0.46540746  0.53015432]\n",
      "svm: 0.57269700333\n",
      "logreg: 0.583795782464\n"
     ]
    }
   ],
   "source": [
    "svm_pred, svm, logreg_pred, logreg  =  runFullStack(d_train, d_train_label, d_test, d_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#runFullStack(d_train, d_train_label, d_test, d_test_label)\n",
    "\n",
    "runFM(d_train, d_train_label, d_test, d_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'hero_id', u'General Rate', u'Early', u'Mid', u'Late',\n",
       "       u'Poly1', u'Poly2', u'Poly3', u'Poly4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_and_rates = pd.read_csv('TimeWinRatesPoly.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polies = [[] for i in range(115)]\n",
    "\n",
    "for index, line in poly_and_rates.iterrows():\n",
    "    \n",
    "    pol = [line[6], line[7], line[8], line[9]]\n",
    "    polies[int(line[1])] = np.poly1d(pol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = d_test[8:9].values[0]\n",
    "print(logreg.predict_proba(t.reshape(1, -1)))\n",
    "for i in range(114, 228):\n",
    "    if t[i] == 1:\n",
    "        t[i] = 2\n",
    "\n",
    "print(logreg.predict_proba(t.reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./ready_models/logreg_picks_rates.pkl',\n",
       " './ready_models/logreg_picks_rates.pkl_01.npy',\n",
       " './ready_models/logreg_picks_rates.pkl_02.npy',\n",
       " './ready_models/logreg_picks_rates.pkl_03.npy',\n",
       " './ready_models/logreg_picks_rates.pkl_04.npy']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(svm, './ready_models/svm_picks_rates.pkl') \n",
    "joblib.dump(logreg, './ready_models/logreg_picks_rates.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calcTeamWinRate(time, pick, polies):\n",
    "    rates = [polies[i](time) for i in pick]\n",
    "    return sum(rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addRanking(data, rank):\n",
    "    avr_rank = 25\n",
    "    data['dire_rank'] = avr_rank\n",
    "    data['radiant_rank'] = avr_rank\n",
    "    for index, row in data.iterrows():\n",
    "        if row['dire_name'] in rank['0'].values:\n",
    "            data.loc[index, 'dire_rank'] = rank[rank['0'] == row['dire_name']]['1'].values[0]\n",
    "        if row['radiant_name'] in rank['0'].values:\n",
    "            data.loc[index, 'radiant_rank'] = rank[rank['0'] == row['radiant_name']]['1'].values[0]        \n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rank = pd.read_csv('rank_.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:18: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "/home/anton/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:20: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_count = 0\n",
    "cool_count = 0\n",
    "for match_string in alldata:\n",
    "    match = json.loads(match_string)\n",
    "    \n",
    "    if True:\n",
    "        match_info =  parseMatch(match, ['match_id', 'radiant_win', 'radiant_name', 'dire_name', 'duration'])\n",
    "        radiant_pick, dire_pick = parsePicsBans(match)\n",
    "        \n",
    "        if match_info['radiant_win']:\n",
    "            known_winner = 1\n",
    "        else: \n",
    "            known_winner = 0\n",
    "            \n",
    "        dire_rank = 25\n",
    "        radiant_rank = 25\n",
    "        if match_info['radiant_name'] in rank['0'].values:\n",
    "            radiant_rank = rank[rank['0'] == match_info['radiant_name'] ]['1'].values[0]\n",
    "        if match_info['dire_name'] in rank['0'].values:\n",
    "            dire_rank = rank[rank['0'] == match_info['dire_name'] ]['1'].values[0]\n",
    "\n",
    "        if abs(dire_rank - radiant_rank) < 3: \n",
    "            total_count += 1\n",
    "            radiant_prop = calcTeamWinRate(match_info['duration'], radiant_pick, polies)\n",
    "            dire_prop = calcTeamWinRate(match_info['duration'], dire_pick, polies)\n",
    "            \n",
    "            if radiant_prop > dire_prop:\n",
    "                winner = 1\n",
    "            else:\n",
    "                winner = 0\n",
    "                \n",
    "            if winner == known_winner:\n",
    "                cool_count+=1\n",
    "                \n",
    "    else:\n",
    "        error_count += 1\n",
    "\n",
    "'CDEC Gaming' in rank['0'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.616"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(cool_count)/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2446"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(alldata[0])['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(polies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6002\n",
       "Name: r_hero_24, dtype: int64"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_hdr.r_hero_24.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
